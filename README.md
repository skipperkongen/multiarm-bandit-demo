# multiarm-bandit-demo

A small demonstration of three simple algorithms for the multi-arm bandit problem

Requires:

- Python 3
- Pandas
- Numpy

Run:

```
python3 demo.py
```

Outputs:

```
# Strategies
explore    7.682451493483219
exploit    8.968238407784087
greedy     9.488354874608259
optimal   10.052427913089582
```


## Reading and viewing material

There exists [different algorithms](https://towardsdatascience.com/a-comparison-of-bandit-algorithms-24b4adfcabb) to solve the multi-arm bandit problem.

<iframe width="560" height="315" src="https://www.youtube.com/embed/e3L4VocZnnQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/e3L4VocZnnQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
