# multiarm-bandit-demo

A small demonstration of three simple algorithms for the multi-arm bandit problem

Requires:

- Python 3
- Pandas
- Numpy

Run:

```
python3 demo.py
```

Outputs:

```
# Strategies
explore    7.682451493483219
exploit    8.968238407784087
greedy     9.488354874608259
optimal   10.052427913089582
```


## Reading and viewing material

There exists [different algorithms](https://towardsdatascience.com/a-comparison-of-bandit-algorithms-24b4adfcabb) to solve the multi-arm bandit problem.

Here are some videos that introduce the topic. I have based this demo on the first one.
- [Introduction](https://youtu.be/e3L4VocZnnQ)
- [Best Multi-Armed Bandit Strategy?](https://youtu.be/FgmMK6RPU1c)
